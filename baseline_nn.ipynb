{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import pandas as pd\n",
    "\n",
    "mat = scipy.io.loadmat(\"/disk/home/metabric/BRCA1View20000.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCGB2A2</th>\n",
       "      <th>MUCL1</th>\n",
       "      <th>SCGB1D2</th>\n",
       "      <th>PIP</th>\n",
       "      <th>LOC648852</th>\n",
       "      <th>DNAJA2</th>\n",
       "      <th>TFF3</th>\n",
       "      <th>S100P</th>\n",
       "      <th>CPB1</th>\n",
       "      <th>CEACAM6</th>\n",
       "      <th>...</th>\n",
       "      <th>LOC641311</th>\n",
       "      <th>LOC645307</th>\n",
       "      <th>IL1RAP</th>\n",
       "      <th>LOC647149</th>\n",
       "      <th>LOC642453</th>\n",
       "      <th>LOC652100</th>\n",
       "      <th>LOC646050</th>\n",
       "      <th>LOC644912</th>\n",
       "      <th>LOC652294</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.365374</td>\n",
       "      <td>5.610561</td>\n",
       "      <td>5.134799</td>\n",
       "      <td>5.735802</td>\n",
       "      <td>5.855315</td>\n",
       "      <td>5.443985</td>\n",
       "      <td>8.005882</td>\n",
       "      <td>5.615179</td>\n",
       "      <td>6.682096</td>\n",
       "      <td>5.756946</td>\n",
       "      <td>...</td>\n",
       "      <td>5.409726</td>\n",
       "      <td>5.420998</td>\n",
       "      <td>5.396492</td>\n",
       "      <td>5.358751</td>\n",
       "      <td>5.424770</td>\n",
       "      <td>5.411055</td>\n",
       "      <td>5.242460</td>\n",
       "      <td>5.197767</td>\n",
       "      <td>5.643537</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>14.330442</td>\n",
       "      <td>7.979139</td>\n",
       "      <td>10.244240</td>\n",
       "      <td>7.138279</td>\n",
       "      <td>9.890661</td>\n",
       "      <td>11.195867</td>\n",
       "      <td>13.511164</td>\n",
       "      <td>10.548596</td>\n",
       "      <td>5.491578</td>\n",
       "      <td>6.805606</td>\n",
       "      <td>...</td>\n",
       "      <td>5.213895</td>\n",
       "      <td>5.167652</td>\n",
       "      <td>5.273045</td>\n",
       "      <td>5.287980</td>\n",
       "      <td>5.398061</td>\n",
       "      <td>5.226934</td>\n",
       "      <td>5.396744</td>\n",
       "      <td>5.352158</td>\n",
       "      <td>5.811813</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>14.388331</td>\n",
       "      <td>6.016715</td>\n",
       "      <td>12.164435</td>\n",
       "      <td>5.272691</td>\n",
       "      <td>6.468386</td>\n",
       "      <td>5.265518</td>\n",
       "      <td>13.386034</td>\n",
       "      <td>8.764722</td>\n",
       "      <td>7.331663</td>\n",
       "      <td>11.967719</td>\n",
       "      <td>...</td>\n",
       "      <td>5.707537</td>\n",
       "      <td>5.327874</td>\n",
       "      <td>5.549589</td>\n",
       "      <td>5.333051</td>\n",
       "      <td>5.368544</td>\n",
       "      <td>5.296182</td>\n",
       "      <td>5.694022</td>\n",
       "      <td>5.459744</td>\n",
       "      <td>5.269015</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>13.111243</td>\n",
       "      <td>7.251862</td>\n",
       "      <td>8.389121</td>\n",
       "      <td>8.664654</td>\n",
       "      <td>10.378585</td>\n",
       "      <td>5.544646</td>\n",
       "      <td>11.159766</td>\n",
       "      <td>8.263224</td>\n",
       "      <td>5.497906</td>\n",
       "      <td>5.923506</td>\n",
       "      <td>...</td>\n",
       "      <td>5.351022</td>\n",
       "      <td>5.009093</td>\n",
       "      <td>5.345468</td>\n",
       "      <td>5.176322</td>\n",
       "      <td>5.326991</td>\n",
       "      <td>5.480259</td>\n",
       "      <td>5.292691</td>\n",
       "      <td>5.242160</td>\n",
       "      <td>5.635111</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>12.243103</td>\n",
       "      <td>7.293489</td>\n",
       "      <td>10.919581</td>\n",
       "      <td>9.566137</td>\n",
       "      <td>8.503568</td>\n",
       "      <td>11.492583</td>\n",
       "      <td>11.531352</td>\n",
       "      <td>9.818938</td>\n",
       "      <td>9.443134</td>\n",
       "      <td>6.889670</td>\n",
       "      <td>...</td>\n",
       "      <td>5.320883</td>\n",
       "      <td>5.487783</td>\n",
       "      <td>5.479967</td>\n",
       "      <td>5.332074</td>\n",
       "      <td>5.273141</td>\n",
       "      <td>5.282872</td>\n",
       "      <td>5.222482</td>\n",
       "      <td>5.186136</td>\n",
       "      <td>5.616094</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2128</td>\n",
       "      <td>7.199176</td>\n",
       "      <td>5.708891</td>\n",
       "      <td>5.672914</td>\n",
       "      <td>14.464282</td>\n",
       "      <td>9.816897</td>\n",
       "      <td>5.604835</td>\n",
       "      <td>13.303832</td>\n",
       "      <td>6.391817</td>\n",
       "      <td>13.010996</td>\n",
       "      <td>8.294409</td>\n",
       "      <td>...</td>\n",
       "      <td>5.695733</td>\n",
       "      <td>5.363557</td>\n",
       "      <td>5.394837</td>\n",
       "      <td>5.442947</td>\n",
       "      <td>5.423763</td>\n",
       "      <td>5.558225</td>\n",
       "      <td>5.575000</td>\n",
       "      <td>5.636068</td>\n",
       "      <td>5.454823</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2129</td>\n",
       "      <td>10.354497</td>\n",
       "      <td>14.464282</td>\n",
       "      <td>7.633244</td>\n",
       "      <td>14.464282</td>\n",
       "      <td>11.294018</td>\n",
       "      <td>5.468214</td>\n",
       "      <td>10.886420</td>\n",
       "      <td>12.260033</td>\n",
       "      <td>5.662372</td>\n",
       "      <td>6.274380</td>\n",
       "      <td>...</td>\n",
       "      <td>5.537254</td>\n",
       "      <td>5.613097</td>\n",
       "      <td>5.254552</td>\n",
       "      <td>5.205904</td>\n",
       "      <td>5.486546</td>\n",
       "      <td>5.206480</td>\n",
       "      <td>5.161718</td>\n",
       "      <td>5.451296</td>\n",
       "      <td>5.215587</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2130</td>\n",
       "      <td>9.294401</td>\n",
       "      <td>13.703049</td>\n",
       "      <td>6.063617</td>\n",
       "      <td>10.063176</td>\n",
       "      <td>5.393440</td>\n",
       "      <td>5.529584</td>\n",
       "      <td>10.937517</td>\n",
       "      <td>12.220400</td>\n",
       "      <td>9.985646</td>\n",
       "      <td>8.370227</td>\n",
       "      <td>...</td>\n",
       "      <td>5.520596</td>\n",
       "      <td>5.572326</td>\n",
       "      <td>5.317225</td>\n",
       "      <td>5.178158</td>\n",
       "      <td>5.316757</td>\n",
       "      <td>5.210332</td>\n",
       "      <td>5.239428</td>\n",
       "      <td>5.395402</td>\n",
       "      <td>5.501265</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2131</td>\n",
       "      <td>14.464282</td>\n",
       "      <td>13.203708</td>\n",
       "      <td>14.169804</td>\n",
       "      <td>13.731721</td>\n",
       "      <td>12.478907</td>\n",
       "      <td>5.347654</td>\n",
       "      <td>14.464282</td>\n",
       "      <td>9.593148</td>\n",
       "      <td>6.165212</td>\n",
       "      <td>11.207149</td>\n",
       "      <td>...</td>\n",
       "      <td>5.650387</td>\n",
       "      <td>5.359733</td>\n",
       "      <td>5.374522</td>\n",
       "      <td>5.245155</td>\n",
       "      <td>5.453742</td>\n",
       "      <td>5.353135</td>\n",
       "      <td>5.235716</td>\n",
       "      <td>5.155543</td>\n",
       "      <td>5.442698</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2132</td>\n",
       "      <td>6.730752</td>\n",
       "      <td>6.879782</td>\n",
       "      <td>6.134414</td>\n",
       "      <td>5.446989</td>\n",
       "      <td>5.320249</td>\n",
       "      <td>10.904521</td>\n",
       "      <td>5.347355</td>\n",
       "      <td>12.784519</td>\n",
       "      <td>5.391796</td>\n",
       "      <td>6.048233</td>\n",
       "      <td>...</td>\n",
       "      <td>5.193949</td>\n",
       "      <td>5.300694</td>\n",
       "      <td>5.545144</td>\n",
       "      <td>5.143987</td>\n",
       "      <td>5.496168</td>\n",
       "      <td>5.236875</td>\n",
       "      <td>5.123631</td>\n",
       "      <td>5.210307</td>\n",
       "      <td>5.456472</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2133 rows Ã— 20001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SCGB2A2      MUCL1    SCGB1D2        PIP  LOC648852     DNAJA2  \\\n",
       "0      6.365374   5.610561   5.134799   5.735802   5.855315   5.443985   \n",
       "1     14.330442   7.979139  10.244240   7.138279   9.890661  11.195867   \n",
       "2     14.388331   6.016715  12.164435   5.272691   6.468386   5.265518   \n",
       "3     13.111243   7.251862   8.389121   8.664654  10.378585   5.544646   \n",
       "4     12.243103   7.293489  10.919581   9.566137   8.503568  11.492583   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "2128   7.199176   5.708891   5.672914  14.464282   9.816897   5.604835   \n",
       "2129  10.354497  14.464282   7.633244  14.464282  11.294018   5.468214   \n",
       "2130   9.294401  13.703049   6.063617  10.063176   5.393440   5.529584   \n",
       "2131  14.464282  13.203708  14.169804  13.731721  12.478907   5.347654   \n",
       "2132   6.730752   6.879782   6.134414   5.446989   5.320249  10.904521   \n",
       "\n",
       "           TFF3      S100P       CPB1    CEACAM6  ...  LOC641311  LOC645307  \\\n",
       "0      8.005882   5.615179   6.682096   5.756946  ...   5.409726   5.420998   \n",
       "1     13.511164  10.548596   5.491578   6.805606  ...   5.213895   5.167652   \n",
       "2     13.386034   8.764722   7.331663  11.967719  ...   5.707537   5.327874   \n",
       "3     11.159766   8.263224   5.497906   5.923506  ...   5.351022   5.009093   \n",
       "4     11.531352   9.818938   9.443134   6.889670  ...   5.320883   5.487783   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "2128  13.303832   6.391817  13.010996   8.294409  ...   5.695733   5.363557   \n",
       "2129  10.886420  12.260033   5.662372   6.274380  ...   5.537254   5.613097   \n",
       "2130  10.937517  12.220400   9.985646   8.370227  ...   5.520596   5.572326   \n",
       "2131  14.464282   9.593148   6.165212  11.207149  ...   5.650387   5.359733   \n",
       "2132   5.347355  12.784519   5.391796   6.048233  ...   5.193949   5.300694   \n",
       "\n",
       "        IL1RAP  LOC647149  LOC642453  LOC652100  LOC646050  LOC644912  \\\n",
       "0     5.396492   5.358751   5.424770   5.411055   5.242460   5.197767   \n",
       "1     5.273045   5.287980   5.398061   5.226934   5.396744   5.352158   \n",
       "2     5.549589   5.333051   5.368544   5.296182   5.694022   5.459744   \n",
       "3     5.345468   5.176322   5.326991   5.480259   5.292691   5.242160   \n",
       "4     5.479967   5.332074   5.273141   5.282872   5.222482   5.186136   \n",
       "...        ...        ...        ...        ...        ...        ...   \n",
       "2128  5.394837   5.442947   5.423763   5.558225   5.575000   5.636068   \n",
       "2129  5.254552   5.205904   5.486546   5.206480   5.161718   5.451296   \n",
       "2130  5.317225   5.178158   5.316757   5.210332   5.239428   5.395402   \n",
       "2131  5.374522   5.245155   5.453742   5.353135   5.235716   5.155543   \n",
       "2132  5.545144   5.143987   5.496168   5.236875   5.123631   5.210307   \n",
       "\n",
       "      LOC652294  label  \n",
       "0      5.643537      6  \n",
       "1      5.811813      4  \n",
       "2      5.269015      4  \n",
       "3      5.635111      5  \n",
       "4      5.616094      3  \n",
       "...         ...    ...  \n",
       "2128   5.454823      3  \n",
       "2129   5.215587      5  \n",
       "2130   5.501265      2  \n",
       "2131   5.442698      5  \n",
       "2132   5.456472      1  \n",
       "\n",
       "[2133 rows x 20001 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_labels = [g[0] for g in mat['gene'][0]]\n",
    "df = pd.DataFrame(mat['data'].transpose(), columns=gene_labels)\n",
    "# df['id'] = mat['id'][0]\n",
    "df['label'] = mat['targets']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# create dataloader\n",
    "class BaselineMetabricDataset(Dataset):\n",
    "    def __init__(self, mat_file):\n",
    "        mat = scipy.io.loadmat(mat_file)\n",
    "        gene_labels = [g[0] for g in mat['gene'][0]]\n",
    "        self.df = pd.DataFrame(mat['data'].transpose(), columns=gene_labels)\n",
    "        # df['id'] = mat['id'][0]\n",
    "        self.df['label'] = mat['targets']\n",
    "        self.df['label'] = self.df['label'] - 1\n",
    "        self.labels = self.df.pop('label')\n",
    "        self.num_classes = 6\n",
    "        \n",
    "        # maybe normalize the columns\n",
    "        self.tensors = {}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if idx in self.tensors:\n",
    "            return self.tensors[idx]\n",
    "        label = torch.zeros(self.num_classes)\n",
    "        label[self.labels[idx]] = 1\n",
    "        sample = (torch.FloatTensor(self.df.iloc[idx, :].values), label)\n",
    "        self.tensors[idx] = sample\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_file = \"/disk/home/metabric/BRCA1View20000.mat\"\n",
    "met_dataset = BaselineMetabricDataset(mat_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2133"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(met_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split, test_split = torch.utils.data.random_split(met_dataset, [1900, 233])\n",
    "train_loader = DataLoader(train_split, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_split, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader))\n",
    "print(len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 31.690187454223633\n",
      "1 33.68888854980469\n",
      "2 29.41666030883789\n",
      "3 29.881725311279297\n",
      "4 30.074764251708984\n",
      "5 32.36648941040039\n",
      "6 30.185632705688477\n",
      "7 30.240121841430664\n",
      "8 26.700206756591797\n",
      "9 25.371135711669922\n",
      "10 25.15553855895996\n",
      "11 25.775842666625977\n",
      "12 26.27074432373047\n",
      "13 24.06377410888672\n",
      "14 29.61651039123535\n",
      "15 23.221153259277344\n",
      "16 23.82718276977539\n",
      "17 21.352779388427734\n",
      "18 23.250396728515625\n",
      "19 22.20803451538086\n",
      "20 24.161170959472656\n",
      "21 20.347013473510742\n",
      "22 23.67109489440918\n",
      "23 20.703014373779297\n",
      "24 21.95526123046875\n",
      "25 20.583215713500977\n",
      "26 21.137752532958984\n",
      "27 22.881820678710938\n",
      "28 23.679471969604492\n",
      "29 21.250619888305664\n",
      "30 18.56313133239746\n",
      "31 21.149890899658203\n",
      "32 18.698150634765625\n",
      "33 23.593774795532227\n",
      "34 22.067312240600586\n",
      "35 20.692705154418945\n",
      "36 19.077468872070312\n",
      "37 19.12200355529785\n",
      "38 22.232967376708984\n",
      "39 17.669448852539062\n",
      "40 16.11856460571289\n",
      "41 20.074800491333008\n",
      "42 21.56955337524414\n",
      "43 24.01909637451172\n",
      "44 19.177433013916016\n",
      "45 16.722436904907227\n",
      "46 18.138662338256836\n",
      "47 21.26171875\n",
      "48 19.438932418823242\n",
      "49 19.8104305267334\n",
      "50 18.919374465942383\n",
      "51 22.235471725463867\n",
      "52 19.92499351501465\n",
      "53 21.264137268066406\n",
      "54 22.367759704589844\n",
      "55 20.729291915893555\n",
      "56 18.059057235717773\n",
      "57 16.94939422607422\n",
      "58 18.289892196655273\n",
      "59 18.220272064208984\n",
      "60 18.294330596923828\n",
      "61 17.392791748046875\n",
      "62 18.714614868164062\n",
      "63 22.45564842224121\n",
      "64 20.375883102416992\n",
      "65 15.392666816711426\n",
      "66 17.02976417541504\n",
      "67 19.92345428466797\n",
      "68 18.686853408813477\n",
      "69 22.087100982666016\n",
      "70 17.16310691833496\n",
      "71 19.132572174072266\n",
      "72 14.466023445129395\n",
      "73 18.289897918701172\n",
      "74 17.41770362854004\n",
      "75 19.31196403503418\n",
      "76 18.186277389526367\n",
      "77 21.952699661254883\n",
      "78 21.177480697631836\n",
      "79 19.149208068847656\n",
      "80 13.724771499633789\n",
      "81 15.92087459564209\n",
      "82 16.41489028930664\n",
      "83 17.751371383666992\n",
      "84 18.197355270385742\n",
      "85 16.00404930114746\n",
      "86 17.787145614624023\n",
      "87 16.707937240600586\n",
      "88 16.933198928833008\n",
      "89 18.792551040649414\n",
      "90 15.7766752243042\n",
      "91 16.354225158691406\n",
      "92 16.5115966796875\n",
      "93 17.669050216674805\n",
      "94 19.49122428894043\n",
      "95 19.010793685913086\n",
      "96 19.09502410888672\n",
      "97 17.379318237304688\n",
      "98 21.194753646850586\n",
      "99 17.500904083251953\n",
      "100 19.16193962097168\n",
      "101 14.479981422424316\n",
      "102 16.228240966796875\n",
      "103 16.822965621948242\n",
      "104 17.308244705200195\n",
      "105 19.449264526367188\n",
      "106 17.38225555419922\n",
      "107 16.440574645996094\n",
      "108 18.099931716918945\n",
      "109 15.328851699829102\n",
      "110 20.85131072998047\n",
      "111 16.254276275634766\n",
      "112 14.55366325378418\n",
      "113 17.832427978515625\n",
      "114 12.997665405273438\n",
      "115 19.746469497680664\n",
      "116 14.306805610656738\n",
      "117 14.185900688171387\n",
      "118 17.61532974243164\n",
      "119 19.59054946899414\n",
      "120 15.94744873046875\n",
      "121 13.920258522033691\n",
      "122 16.887508392333984\n",
      "123 16.905242919921875\n",
      "124 18.18414306640625\n",
      "125 20.691579818725586\n",
      "126 17.75404930114746\n",
      "127 16.543304443359375\n",
      "128 13.1351318359375\n",
      "129 13.865473747253418\n",
      "130 16.704002380371094\n",
      "131 14.535303115844727\n",
      "132 13.201873779296875\n",
      "133 16.5605525970459\n",
      "134 23.4420108795166\n",
      "135 16.130830764770508\n",
      "136 17.051738739013672\n",
      "137 13.359953880310059\n",
      "138 17.52975845336914\n",
      "139 15.563618659973145\n",
      "140 27.527021408081055\n",
      "141 17.08694076538086\n",
      "142 15.762158393859863\n",
      "143 13.92935848236084\n",
      "144 17.235544204711914\n",
      "145 17.061294555664062\n",
      "146 14.893248558044434\n",
      "147 15.59918212890625\n",
      "148 17.506174087524414\n",
      "149 18.584951400756836\n",
      "150 17.12928581237793\n",
      "151 14.56867790222168\n",
      "152 16.73930549621582\n",
      "153 14.480305671691895\n",
      "154 19.500581741333008\n",
      "155 11.921130180358887\n",
      "156 15.026772499084473\n",
      "157 21.643220901489258\n",
      "158 15.992645263671875\n",
      "159 14.398336410522461\n",
      "160 12.315464973449707\n",
      "161 13.317009925842285\n",
      "162 14.204586029052734\n",
      "163 15.979084014892578\n",
      "164 20.542770385742188\n",
      "165 16.642566680908203\n",
      "166 16.766794204711914\n",
      "167 15.262166023254395\n",
      "168 14.770044326782227\n",
      "169 19.297636032104492\n",
      "170 15.30611801147461\n",
      "171 12.290586471557617\n",
      "172 13.791703224182129\n",
      "173 14.717074394226074\n",
      "174 15.8368501663208\n",
      "175 17.872581481933594\n",
      "176 12.733391761779785\n",
      "177 16.40736961364746\n",
      "178 16.403156280517578\n",
      "179 15.110223770141602\n",
      "180 15.867385864257812\n",
      "181 12.030097007751465\n",
      "182 13.848396301269531\n",
      "183 15.246939659118652\n",
      "184 19.320594787597656\n",
      "185 15.835651397705078\n",
      "186 16.506473541259766\n",
      "187 16.7465877532959\n",
      "188 14.241243362426758\n",
      "189 16.167659759521484\n",
      "190 16.054664611816406\n",
      "191 18.35434341430664\n",
      "192 15.511242866516113\n",
      "193 14.395696640014648\n",
      "194 12.096665382385254\n",
      "195 13.229110717773438\n",
      "196 14.78230094909668\n",
      "197 15.010887145996094\n",
      "198 16.431560516357422\n",
      "199 16.251375198364258\n",
      "200 19.00759506225586\n",
      "201 12.31435775756836\n",
      "202 14.730859756469727\n",
      "203 17.830791473388672\n",
      "204 17.10585594177246\n",
      "205 14.320775032043457\n",
      "206 12.535024642944336\n",
      "207 15.39134407043457\n",
      "208 17.169023513793945\n",
      "209 13.26572036743164\n",
      "210 9.029854774475098\n",
      "211 16.82025718688965\n",
      "212 13.985522270202637\n",
      "213 15.838669776916504\n",
      "214 15.244338989257812\n",
      "215 14.447020530700684\n",
      "216 17.744651794433594\n",
      "217 14.00058364868164\n",
      "218 16.385826110839844\n",
      "219 13.006720542907715\n",
      "220 11.776049613952637\n",
      "221 12.990159034729004\n",
      "222 17.014131546020508\n",
      "223 16.04429054260254\n",
      "224 13.31128978729248\n",
      "225 14.572426795959473\n",
      "226 17.674076080322266\n",
      "227 16.043655395507812\n",
      "228 16.410289764404297\n",
      "229 14.95146369934082\n",
      "230 12.300009727478027\n",
      "231 14.958602905273438\n",
      "232 13.983979225158691\n",
      "233 14.30195140838623\n",
      "234 13.025784492492676\n",
      "235 15.131987571716309\n",
      "236 14.236394882202148\n",
      "237 13.53286361694336\n",
      "238 13.668606758117676\n",
      "239 13.083636283874512\n",
      "240 12.9108304977417\n",
      "241 16.303131103515625\n",
      "242 11.43628215789795\n",
      "243 10.608367919921875\n",
      "244 15.471433639526367\n",
      "245 12.669731140136719\n",
      "246 14.306588172912598\n",
      "247 12.518719673156738\n",
      "248 13.363551139831543\n",
      "249 14.64781665802002\n",
      "250 18.224382400512695\n",
      "251 12.133018493652344\n",
      "252 11.390568733215332\n",
      "253 11.620062828063965\n",
      "254 13.321654319763184\n",
      "255 13.635320663452148\n",
      "256 14.755470275878906\n",
      "257 9.046713829040527\n",
      "258 14.030330657958984\n",
      "259 18.11760139465332\n",
      "260 11.624056816101074\n",
      "261 10.459221839904785\n",
      "262 11.413905143737793\n",
      "263 10.57322883605957\n",
      "264 15.641162872314453\n",
      "265 10.41707992553711\n",
      "266 15.092896461486816\n",
      "267 16.661439895629883\n",
      "268 12.304457664489746\n",
      "269 12.434349060058594\n",
      "270 11.087492942810059\n",
      "271 12.461321830749512\n",
      "272 15.927634239196777\n",
      "273 11.291391372680664\n",
      "274 11.844963073730469\n",
      "275 11.42988395690918\n",
      "276 12.594954490661621\n",
      "277 10.945550918579102\n",
      "278 15.857196807861328\n",
      "279 8.921110153198242\n",
      "280 12.329694747924805\n",
      "281 10.538748741149902\n",
      "282 17.197294235229492\n",
      "283 13.41707706451416\n",
      "284 10.037667274475098\n",
      "285 9.414462089538574\n",
      "286 12.551025390625\n",
      "287 11.414010047912598\n",
      "288 10.251789093017578\n",
      "289 10.348310470581055\n",
      "290 14.325582504272461\n",
      "291 11.529589653015137\n",
      "292 11.809340476989746\n",
      "293 11.761326789855957\n",
      "294 11.437355995178223\n",
      "295 14.410032272338867\n",
      "296 14.674433708190918\n",
      "297 12.128061294555664\n",
      "298 9.790167808532715\n",
      "299 11.95174503326416\n"
     ]
    }
   ],
   "source": [
    "IN_DIM = 20000\n",
    "OUT_DIM = 6\n",
    "LEARNING_RATE = 1e-5\n",
    "N_EPOCHS = 300\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(IN_DIM, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1024, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, OUT_DIM)\n",
    ")\n",
    "\n",
    "# loss_fn = nn.MSELoss(reduction='sum')\n",
    "# loss_fun = nn.SmoothL1Loss()\n",
    "loss_fun = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    loss = None\n",
    "    for i, (X, y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(epoch, loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 0, 2, 2, 2, 3, 2, 1, 4, 3, 0, 3, 1, 5, 3, 2, 4, 2, 2, 2, 3, 2, 4, 2,\n",
      "        2, 4, 2, 2, 0, 3, 3, 3, 3, 2, 2, 0, 4, 3, 1, 4, 2, 3, 3, 3, 2, 2, 2, 3,\n",
      "        2, 0, 0, 4, 2, 2, 3, 0, 3, 2, 2, 0, 3, 2, 2, 2])\n",
      "tensor([5, 0, 2, 2, 2, 3, 2, 1, 4, 2, 0, 3, 1, 5, 3, 1, 4, 2, 2, 4, 3, 2, 4, 2,\n",
      "        2, 4, 2, 2, 0, 3, 3, 3, 3, 3, 2, 0, 0, 3, 0, 2, 2, 3, 3, 3, 2, 2, 2, 3,\n",
      "        5, 1, 0, 4, 2, 3, 1, 0, 3, 2, 2, 0, 3, 2, 4, 2])\n",
      "---------------------------------\n",
      "tensor([1, 2, 3, 1, 3, 0, 1, 3, 2, 5, 2, 2, 2, 2, 0, 2, 3, 3, 2, 5, 5, 2, 2, 2,\n",
      "        2, 5, 2, 4, 4, 1, 2, 5, 2, 2, 0, 2, 3, 2, 0, 2, 3, 2, 3, 4, 3, 3, 2, 2,\n",
      "        2, 1, 3, 2, 2, 3, 3, 0, 1, 2, 3, 2, 2, 3, 3, 3])\n",
      "tensor([0, 2, 3, 1, 3, 0, 1, 3, 3, 5, 2, 2, 3, 2, 0, 3, 3, 3, 2, 5, 5, 2, 2, 2,\n",
      "        2, 5, 2, 4, 4, 1, 2, 5, 2, 2, 0, 2, 3, 2, 0, 2, 3, 2, 3, 4, 3, 3, 2, 2,\n",
      "        2, 0, 3, 2, 2, 3, 3, 0, 3, 2, 3, 2, 2, 3, 3, 3])\n",
      "---------------------------------\n",
      "tensor([3, 2, 2, 2, 3, 3, 3, 2, 2, 2, 3, 0, 2, 2, 3, 2, 1, 2, 2, 4, 0, 4, 5, 5,\n",
      "        2, 0, 2, 1, 2, 2, 2, 1, 3, 3, 2, 2, 0, 2, 3, 2, 3, 2, 3, 3, 0, 3, 3, 4,\n",
      "        5, 2, 4, 1, 2, 3, 3, 0, 2, 1, 2, 2, 3, 3, 2, 2])\n",
      "tensor([3, 2, 2, 2, 3, 3, 3, 2, 2, 3, 3, 0, 3, 2, 3, 2, 1, 2, 3, 0, 0, 4, 5, 5,\n",
      "        2, 0, 3, 1, 2, 2, 2, 1, 3, 3, 2, 2, 0, 2, 3, 2, 3, 2, 3, 2, 0, 3, 3, 4,\n",
      "        5, 4, 4, 1, 2, 1, 3, 0, 4, 1, 2, 3, 3, 1, 2, 2])\n",
      "---------------------------------\n",
      "tensor([3, 5, 3, 1, 3, 1, 1, 2, 3, 2, 4, 2, 1, 4, 2, 1, 2, 1, 0, 2, 2, 0, 2, 3,\n",
      "        2, 3, 4, 3, 1, 2, 2, 2, 0, 2, 2, 4, 2, 2, 0, 2, 2])\n",
      "tensor([2, 5, 2, 1, 3, 1, 1, 2, 3, 2, 4, 3, 1, 4, 2, 1, 2, 1, 0, 2, 3, 0, 2, 3,\n",
      "        2, 1, 4, 3, 1, 2, 3, 3, 0, 2, 2, 4, 2, 2, 0, 2, 2])\n",
      "---------------------------------\n",
      "Accuracy: 197 / 233 84.55%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.81      0.88        27\n",
      "           1       0.81      0.74      0.77        23\n",
      "           2       0.80      0.94      0.87        86\n",
      "           3       0.86      0.77      0.82        66\n",
      "           4       0.83      0.79      0.81        19\n",
      "           5       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.85       233\n",
      "   macro avg       0.88      0.83      0.85       233\n",
      "weighted avg       0.85      0.85      0.84       233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "y_true = []\n",
    "predicted = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X, y in test_loader:\n",
    "        predictions = model(X)\n",
    "        _, pred = torch.max(predictions.data, 1)\n",
    "        _, labeled = torch.max(y.data, 1)\n",
    "        total += y.size(0)\n",
    "        correct += (pred == labeled).sum().item()\n",
    "        y_true.extend(labeled)\n",
    "        predicted.extend(pred)\n",
    "        print(pred)\n",
    "        print(labeled)\n",
    "        print(\"---------------------------------\")\n",
    "print(f\"Accuracy: {correct} / {total} {100 * correct / total:.2f}%\")\n",
    "\n",
    "\n",
    "print(classification_report(y_true, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'baseline_model_v0.4.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
