{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2133\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "mat = scipy.io.loadmat('../Neural-Graph-Machine-Experiment/BRCA1View20000.mat')\n",
    "mat = {k:v for k, v in mat.items() if k[0] != '_'}\n",
    "print(len(mat['targets']))\n",
    "#mat = {k: pd.Series(v[0]) for k, v in mat.items() if len(v) == 0}\n",
    "mat = {k: pd.Series(v.flatten()) for k, v in mat.items()}\n",
    "\n",
    "targets = pd.DataFrame.from_dict(mat).dropna()[['id', 'targets']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2080.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>236.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>741.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>380.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1446.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>1880.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>858.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130</th>\n",
       "      <td>698.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131</th>\n",
       "      <td>1626.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132</th>\n",
       "      <td>694.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2133 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  targets\n",
       "0     2080.0      6.0\n",
       "1      236.0      4.0\n",
       "2      741.0      4.0\n",
       "3      380.0      5.0\n",
       "4     1446.0      3.0\n",
       "...      ...      ...\n",
       "2128  1880.0      3.0\n",
       "2129   858.0      5.0\n",
       "2130   698.0      2.0\n",
       "2131  1626.0      5.0\n",
       "2132   694.0      1.0\n",
       "\n",
       "[2133 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "url=\"https://metabric.s3-us-west-1.amazonaws.com/cat2vec/cat2vec_adj.csv\"\n",
    "s=requests.get(url).content\n",
    "c=pd.read_csv(io.StringIO(s.decode('utf-8')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "c['id'] = c['Patient ID'].apply(lambda x: float(x.split(\"-\")[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = c.merge(targets, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>MB-0002</th>\n",
       "      <th>MB-0005</th>\n",
       "      <th>MB-0006</th>\n",
       "      <th>MB-0008</th>\n",
       "      <th>MB-0010</th>\n",
       "      <th>MB-0014</th>\n",
       "      <th>MB-0020</th>\n",
       "      <th>MB-0022</th>\n",
       "      <th>MB-0028</th>\n",
       "      <th>...</th>\n",
       "      <th>MB-7292</th>\n",
       "      <th>MB-7293</th>\n",
       "      <th>MB-7294</th>\n",
       "      <th>MB-7295</th>\n",
       "      <th>MB-7296</th>\n",
       "      <th>MB-7297</th>\n",
       "      <th>MB-7298</th>\n",
       "      <th>MB-7299</th>\n",
       "      <th>id</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MB-0002</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.049814</td>\n",
       "      <td>0.294911</td>\n",
       "      <td>0.039187</td>\n",
       "      <td>-0.249322</td>\n",
       "      <td>0.348728</td>\n",
       "      <td>0.211491</td>\n",
       "      <td>0.074908</td>\n",
       "      <td>0.039009</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.720671</td>\n",
       "      <td>-0.716318</td>\n",
       "      <td>-0.727589</td>\n",
       "      <td>-0.689906</td>\n",
       "      <td>-0.714645</td>\n",
       "      <td>-0.685676</td>\n",
       "      <td>-0.285254</td>\n",
       "      <td>-0.367773</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MB-0005</td>\n",
       "      <td>0.049814</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.724841</td>\n",
       "      <td>-0.828614</td>\n",
       "      <td>0.055709</td>\n",
       "      <td>-0.629857</td>\n",
       "      <td>-0.549421</td>\n",
       "      <td>0.352115</td>\n",
       "      <td>0.405221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124283</td>\n",
       "      <td>0.078778</td>\n",
       "      <td>0.049550</td>\n",
       "      <td>0.081636</td>\n",
       "      <td>0.056126</td>\n",
       "      <td>0.119477</td>\n",
       "      <td>0.023581</td>\n",
       "      <td>0.294524</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MB-0006</td>\n",
       "      <td>0.294911</td>\n",
       "      <td>-0.724841</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.655585</td>\n",
       "      <td>-0.232813</td>\n",
       "      <td>-0.822487</td>\n",
       "      <td>-0.300468</td>\n",
       "      <td>0.200873</td>\n",
       "      <td>0.301604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370188</td>\n",
       "      <td>0.358792</td>\n",
       "      <td>0.361032</td>\n",
       "      <td>0.400041</td>\n",
       "      <td>0.332867</td>\n",
       "      <td>0.401476</td>\n",
       "      <td>-0.217995</td>\n",
       "      <td>0.577451</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MB-0008</td>\n",
       "      <td>0.039187</td>\n",
       "      <td>-0.828614</td>\n",
       "      <td>-0.655585</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.045452</td>\n",
       "      <td>-0.591871</td>\n",
       "      <td>-0.578162</td>\n",
       "      <td>0.348633</td>\n",
       "      <td>0.398693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066668</td>\n",
       "      <td>0.043555</td>\n",
       "      <td>-0.005104</td>\n",
       "      <td>0.041898</td>\n",
       "      <td>0.037544</td>\n",
       "      <td>0.076997</td>\n",
       "      <td>0.045441</td>\n",
       "      <td>0.263049</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MB-0010</td>\n",
       "      <td>-0.249322</td>\n",
       "      <td>0.055709</td>\n",
       "      <td>-0.232813</td>\n",
       "      <td>0.045452</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.291201</td>\n",
       "      <td>0.505300</td>\n",
       "      <td>-0.075984</td>\n",
       "      <td>-0.028591</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.122636</td>\n",
       "      <td>-0.145899</td>\n",
       "      <td>-0.112173</td>\n",
       "      <td>-0.087051</td>\n",
       "      <td>-0.170112</td>\n",
       "      <td>-0.139419</td>\n",
       "      <td>-0.726025</td>\n",
       "      <td>0.322615</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>MB-0899</td>\n",
       "      <td>0.358629</td>\n",
       "      <td>-0.644874</td>\n",
       "      <td>-0.839664</td>\n",
       "      <td>-0.614083</td>\n",
       "      <td>-0.248022</td>\n",
       "      <td>-0.849860</td>\n",
       "      <td>-0.239179</td>\n",
       "      <td>0.217811</td>\n",
       "      <td>0.340402</td>\n",
       "      <td>...</td>\n",
       "      <td>0.433729</td>\n",
       "      <td>0.435154</td>\n",
       "      <td>0.423822</td>\n",
       "      <td>0.484754</td>\n",
       "      <td>0.411553</td>\n",
       "      <td>0.445852</td>\n",
       "      <td>-0.226774</td>\n",
       "      <td>0.656499</td>\n",
       "      <td>899.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>MB-0901</td>\n",
       "      <td>0.242280</td>\n",
       "      <td>-0.529859</td>\n",
       "      <td>-0.288746</td>\n",
       "      <td>-0.554857</td>\n",
       "      <td>0.512799</td>\n",
       "      <td>-0.200528</td>\n",
       "      <td>-0.870553</td>\n",
       "      <td>-0.111523</td>\n",
       "      <td>-0.103842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175758</td>\n",
       "      <td>0.184256</td>\n",
       "      <td>0.165979</td>\n",
       "      <td>0.167945</td>\n",
       "      <td>0.178024</td>\n",
       "      <td>0.222212</td>\n",
       "      <td>0.482043</td>\n",
       "      <td>-0.190859</td>\n",
       "      <td>901.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>MB-0904</td>\n",
       "      <td>-0.341442</td>\n",
       "      <td>-0.003104</td>\n",
       "      <td>-0.200454</td>\n",
       "      <td>0.028634</td>\n",
       "      <td>-0.730339</td>\n",
       "      <td>-0.238811</td>\n",
       "      <td>0.476475</td>\n",
       "      <td>-0.087855</td>\n",
       "      <td>-0.068353</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.216419</td>\n",
       "      <td>-0.236150</td>\n",
       "      <td>-0.187077</td>\n",
       "      <td>-0.185078</td>\n",
       "      <td>-0.284451</td>\n",
       "      <td>-0.221002</td>\n",
       "      <td>-0.722680</td>\n",
       "      <td>0.235831</td>\n",
       "      <td>904.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>MB-0906</td>\n",
       "      <td>-0.358780</td>\n",
       "      <td>0.316354</td>\n",
       "      <td>0.633718</td>\n",
       "      <td>0.272523</td>\n",
       "      <td>0.355880</td>\n",
       "      <td>0.660196</td>\n",
       "      <td>-0.188703</td>\n",
       "      <td>-0.357670</td>\n",
       "      <td>-0.469261</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.439664</td>\n",
       "      <td>-0.425679</td>\n",
       "      <td>-0.408315</td>\n",
       "      <td>-0.455820</td>\n",
       "      <td>-0.368534</td>\n",
       "      <td>-0.435420</td>\n",
       "      <td>0.294628</td>\n",
       "      <td>-0.781983</td>\n",
       "      <td>906.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>MB-0907</td>\n",
       "      <td>-0.151527</td>\n",
       "      <td>-0.105369</td>\n",
       "      <td>-0.104822</td>\n",
       "      <td>-0.079890</td>\n",
       "      <td>-0.159456</td>\n",
       "      <td>-0.078519</td>\n",
       "      <td>0.232172</td>\n",
       "      <td>0.275099</td>\n",
       "      <td>0.322122</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051180</td>\n",
       "      <td>-0.076522</td>\n",
       "      <td>-0.067582</td>\n",
       "      <td>-0.046996</td>\n",
       "      <td>-0.141493</td>\n",
       "      <td>-0.091777</td>\n",
       "      <td>-0.113077</td>\n",
       "      <td>0.213609</td>\n",
       "      <td>907.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>494 rows Ã— 1920 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Patient ID   MB-0002   MB-0005   MB-0006   MB-0008   MB-0010   MB-0014  \\\n",
       "0      MB-0002 -1.000000  0.049814  0.294911  0.039187 -0.249322  0.348728   \n",
       "1      MB-0005  0.049814 -1.000000 -0.724841 -0.828614  0.055709 -0.629857   \n",
       "2      MB-0006  0.294911 -0.724841 -1.000000 -0.655585 -0.232813 -0.822487   \n",
       "3      MB-0008  0.039187 -0.828614 -0.655585 -1.000000  0.045452 -0.591871   \n",
       "4      MB-0010 -0.249322  0.055709 -0.232813  0.045452 -1.000000 -0.291201   \n",
       "..         ...       ...       ...       ...       ...       ...       ...   \n",
       "489    MB-0899  0.358629 -0.644874 -0.839664 -0.614083 -0.248022 -0.849860   \n",
       "490    MB-0901  0.242280 -0.529859 -0.288746 -0.554857  0.512799 -0.200528   \n",
       "491    MB-0904 -0.341442 -0.003104 -0.200454  0.028634 -0.730339 -0.238811   \n",
       "492    MB-0906 -0.358780  0.316354  0.633718  0.272523  0.355880  0.660196   \n",
       "493    MB-0907 -0.151527 -0.105369 -0.104822 -0.079890 -0.159456 -0.078519   \n",
       "\n",
       "      MB-0020   MB-0022   MB-0028  ...   MB-7292   MB-7293   MB-7294  \\\n",
       "0    0.211491  0.074908  0.039009  ... -0.720671 -0.716318 -0.727589   \n",
       "1   -0.549421  0.352115  0.405221  ...  0.124283  0.078778  0.049550   \n",
       "2   -0.300468  0.200873  0.301604  ...  0.370188  0.358792  0.361032   \n",
       "3   -0.578162  0.348633  0.398693  ...  0.066668  0.043555 -0.005104   \n",
       "4    0.505300 -0.075984 -0.028591  ... -0.122636 -0.145899 -0.112173   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "489 -0.239179  0.217811  0.340402  ...  0.433729  0.435154  0.423822   \n",
       "490 -0.870553 -0.111523 -0.103842  ...  0.175758  0.184256  0.165979   \n",
       "491  0.476475 -0.087855 -0.068353  ... -0.216419 -0.236150 -0.187077   \n",
       "492 -0.188703 -0.357670 -0.469261  ... -0.439664 -0.425679 -0.408315   \n",
       "493  0.232172  0.275099  0.322122  ... -0.051180 -0.076522 -0.067582   \n",
       "\n",
       "      MB-7295   MB-7296   MB-7297   MB-7298   MB-7299     id  targets  \n",
       "0   -0.689906 -0.714645 -0.685676 -0.285254 -0.367773    2.0      5.0  \n",
       "1    0.081636  0.056126  0.119477  0.023581  0.294524    5.0      4.0  \n",
       "2    0.400041  0.332867  0.401476 -0.217995  0.577451    6.0      2.0  \n",
       "3    0.041898  0.037544  0.076997  0.045441  0.263049    8.0      3.0  \n",
       "4   -0.087051 -0.170112 -0.139419 -0.726025  0.322615   10.0      1.0  \n",
       "..        ...       ...       ...       ...       ...    ...      ...  \n",
       "489  0.484754  0.411553  0.445852 -0.226774  0.656499  899.0      4.0  \n",
       "490  0.167945  0.178024  0.222212  0.482043 -0.190859  901.0      1.0  \n",
       "491 -0.185078 -0.284451 -0.221002 -0.722680  0.235831  904.0      1.0  \n",
       "492 -0.455820 -0.368534 -0.435420  0.294628 -0.781983  906.0      3.0  \n",
       "493 -0.046996 -0.141493 -0.091777 -0.113077  0.213609  907.0      1.0  \n",
       "\n",
       "[494 rows x 1920 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Neural Network Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import scipy\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[data.columns[1:-2]], data['targets'], test_size=0.33, random_state=42)\n",
    "X_train = torch.tensor(X_train.values).float()\n",
    "y_train = torch.tensor(y_train.values).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = torch.tensor(X_test.values).float()\n",
    "y_test = torch.tensor(y_test.values).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class MyDataset(Dataset):\n",
    "  def __init__(self, values, labels):\n",
    "    super(MyDataset, self).__init__()\n",
    "    self.values = values\n",
    "    self.labels = labels\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.values)  # number of samples in the dataset\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    return self.values[index], self.labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dataset = MyDataset(X_train, y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "testset = MyDataset(X_test, y_test)\n",
    "testloader = DataLoader(testset, batch_size=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network related parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 1917   # The image size = 1x10312 = 10312\n",
    "hidden_size = 50       # The number of nodes at the hidden layer\n",
    "num_classes = 6       # The number of output classes. In this case, from 1 to 39\n",
    "num_epochs = 5         # The number of times entire dataset is trained\n",
    "batch_size = 5       # The size of input data took for one iteration\n",
    "learning_rate = 0.001  # The speed of convergence\n",
    "train_test_split = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(Net, self).__init__()                    # Inherited from the parent class nn.Module\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  # 1st Full-Connected Layer: 10312 (input data) -> 50 (hidden node)\n",
    "        self.relu = nn.ReLU()                          # Non-Linear ReLU Layer: max(0,x)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes) # 2nd Full-Connected Layer: 50 (hidden node) -> 39 (output class)\n",
    "    \n",
    "    def forward(self, x):                              # Forward pass: stacking each layer together\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(input_size, hidden_size, num_classes)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [20/66], Loss: 1.6189\n",
      "Epoch [2/5], Step [20/66], Loss: 1.6227\n",
      "Epoch [3/5], Step [20/66], Loss: 1.6009\n",
      "Epoch [4/5], Step [20/66], Loss: 1.6205\n",
      "Epoch [5/5], Step [20/66], Loss: 1.6015\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "#for epoch in range(0,1):\n",
    "    for i, (images, labels) in enumerate(dataloader):   # Load a batch of images with its (index, data, class)\n",
    "        images = Variable(images)         # Convert torch tensor to Variable: change image from a vector of size 784 to a matrix of 28 x 28\n",
    "        #print(images.shape)\n",
    "        #print(labels)\n",
    "        #print(i)\n",
    "        labels = [i-1 for i in labels]\n",
    "        #print(torch.tensor(labels).reshape(-1, 1).flatten())\n",
    "        labels = Variable(torch.tensor(labels).reshape(-1, 1).flatten())\n",
    "        \n",
    "        optimizer.zero_grad()                             # Intialize the hidden weight to all zeros\n",
    "        outputs = model(images.float())                             # Forward pass: compute the output class given a image\n",
    "        #if epoch == num_epochs-1:\n",
    "        #    print(outputs, labels.long())\n",
    "        loss = criterion(outputs, labels.long())                 # Compute the loss: difference between the output class and the pre-given label\n",
    "        \n",
    "        loss.backward()                                   # Backward pass: compute the weight\n",
    "        optimizer.step()                                  # Optimizer: update the weights of hidden nodes\n",
    "\n",
    "        if (i+1) % 20 == 0:                              # Logging\n",
    "            print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f' %(epoch+1, num_epochs, i+1, len(dataset)//batch_size, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 34 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "all_predicted = []\n",
    "all_labels = []\n",
    "for i, (images, labels) in enumerate(testloader):\n",
    "    images = Variable(images)\n",
    "    outputs = model(images.float()) \n",
    "    labels = [i-1 for i in labels]\n",
    "    labels = torch.tensor(labels).reshape(-1, 1).flatten()\n",
    "    _, predicted = torch.max(outputs.data, 1)  # Choose the best class from the output: The class with the best score\n",
    "    total += labels.size(0)                    # Increment the total count\n",
    "    correct += (predicted == labels).sum()     # Increment the correct count\n",
    "    all_predicted += list(predicted)\n",
    "    #all_labels += (labels)\n",
    "    \n",
    "    \n",
    "print('Accuracy: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into train/test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
